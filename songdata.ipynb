{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is an exploratory journey into the poetic world of one of the legendary bands in the history of rock. \n",
    "# It's an inevitably shallow approach to understanding a music band simply based on a collection of lyrics, \n",
    "# but I hope it would be at least a fun ride and an interesting experience in textual analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('songdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['artist', 'song', 'link', 'text'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df[['artist', 'song', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl   \n",
       "1   ABBA       Andante, Andante   \n",
       "2   ABBA         As Good As New   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(doors) == 97\n",
    "doors = df[df['artist'] == 'Doors']['text']\n",
    "len(doors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "songs = [doors.iloc[i] for i in range(len(doors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This pandas series contains all the songs The Doors created during their period of activity. In total there\n",
    "# are 97 songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"All hail the American night!  \\n  \\nWhat was that?  \\nI don't know  \\nSounds like guns, thunder.  \\n  \\nAlright! Alright! Alright!  \\nHey, listen! Listen! Listen, man! listen, man!  \\nI don't know how many you people believe in astrology  \\nYeah, that's right, that's right, baby, I, I am a  \\nSagittarius  \\nThe most philosophical of all the signs  \\nBut anyway, I don't believe in it  \\nI think it's a bunch of bullshit, myself  \\nBut I tell you this, man, I tell you this  \\nI don't know what's gonna happen, man,  \\nBut I want to have my kicks  \\nBefore the whole shithouse goes up in flames  \\nAlright!\\n\\n\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's get rid of some of this noise so we could get to the content\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer('\\w+')\n",
    "\n",
    "for i in range(len(songs)):\n",
    "    songs[i] = tokenizer.tokenize(songs[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trying to get rid of the stopwords. However certain characters would still remain there\n",
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "nlp.vocab[\"'t\"].is_stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so we need to write a custom filter...\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english') + \n",
    "                [\"n't\", \"'s\", \"'m\", \"'t\", \"'re\", \"yeah\", \"ya\", \"oh\", \"l\", \"la\"] + list(ENGLISH_STOP_WORDS))\n",
    "songs = [list(filter(lambda x: x.lower() not in stopwords, song)) for song in songs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mon',\n",
       " 'set',\n",
       " 'free',\n",
       " 'said',\n",
       " 'warden',\n",
       " 'warden',\n",
       " 'warden',\n",
       " 'break',\n",
       " 'lock',\n",
       " 'key',\n",
       " 'said',\n",
       " 'warden',\n",
       " 'warden',\n",
       " 'warden',\n",
       " 'break',\n",
       " 'lock',\n",
       " 'key',\n",
       " 'come',\n",
       " 'mister',\n",
       " 'c']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[2][10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<wordcloud.wordcloud.WordCloud at 0x7fd4a8758b00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks a bit better, but still there are some single character tokens and words with little semantic content\n",
    "# like 'Yeah' and 'ya'. On the other hand there are some repetitions like 'warden' that pose a challenge to \n",
    "# our semantic analysis since they might be simply there for the purposes of rythm and music, and don't  \n",
    "# necessarily bear a heavy weight with regards to the overall message conveyed in a song. To counter that we \n",
    "# will later use tf-idf. However for now and before we proceed further, let's create a word cloud from all \n",
    "# the words in the lyrics:\n",
    "\n",
    "# we're flattening the nested list containing all the words\n",
    "lyrics = \" \".join([words for song in songs for words in song])\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "jim_mask = np.array(Image.open(\"jim.jpg\"))\n",
    "wc = WordCloud(background_color=\"white\", max_words=3000, mask=jim_mask)\n",
    "wc.generate(lyrics)\n",
    "\n",
    "# wc.to_file(\"jim_cloud.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"jim_cloud.png\" height=\"700\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nice wordcloud, ain't it? Call me crazy but it kinda looks like Jim himself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we came this far, how about looking at concordances of words in The Doors's lyrics. In other words, we'd like to see what words are more likely to come together in the band's lyrics. For this we first resort to creating dense word vectors using word2vec and then we will use the dimensionality reduction technique t-sne to map the vectors to a two-dimensional space where we can plot them on a 2D plane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim, re, matplotlib\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# when training the word2vec model, we only consider words that occurred at least min_count=30 times\n",
    "model = Word2Vec(songs, window=5, size=300, workers=-1, min_count=30)\n",
    "labels = []\n",
    "tokens = []\n",
    "\n",
    "for word in model.wv.vocab:\n",
    "    tokens.append(model[word])\n",
    "    labels.append(word)\n",
    "# TSNE plot to find the similarity of words\n",
    "tsne_model = TSNE(perplexity=30, n_components=2, init='pca', n_iter=5000)\n",
    "new_values = tsne_model.fit_transform(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "for value in new_values:\n",
    "    x.append(value[0])\n",
    "    y.append(value[1])\n",
    "plt.figure(figsize=(16, 12)) \n",
    "for i in range(len(x)):\n",
    "    plt.scatter(x[i],y[i])\n",
    "    plt.annotate(labels[i],\n",
    "                 xy=(x[i], y[i]),\n",
    "                 xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "                 ha='right',\n",
    "                 va='bottom')\n",
    "# plt.savefig('30_most_frequent.png');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"30_most_frequent_1.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again call me nuts, but sounds like a vague touch of Jim is still lurking in the background of this plot. If you squint, you might see him.\n",
    "\n",
    "You will get different results in separate runs, so we can't take the plot too seriously, but nonetheless there are some interesting recurring patterns. So, these words are the most prominent motifs in the band's lyrics. Both <i>man</i> and <i>night</i> occur on the plot, and they actually are adjacent in some of the runs. They remind me of the famous story of Jim witnessing a car accident involving American Indians. <i>end</i> and <i>time</i> also occur next to each other, for which <a href=\"https://en.wikipedia.org/wiki/The_End_(The_Doors_song)\">the connotations are clear</a>.  \n",
    "\n",
    "The relative distance between the words can be interpretted in several ways. In some cases they correspond to semantic similarity (<i>need</i> and <i>want</i> or <i>ride</i> and <i>roll</i>), and in other cases I assume, it translates to the selectional preferences of verbs. For instance the verbs <i>got</i>, <i>gonna</i>, and <i>gotta</i> are placed in relative closeness to <i>roll</i> and <i>ride</i>. Same goes for the verbs <i>come</i> and <i>tell</i> being close to the noun <i>baby</i>.\n",
    "\n",
    "The next plot is what we get in a subsequent run. In each run, we see different patterns that we can interpret the way we want only to reinforce our own preconceptions about the band. There was a little bug in the code when I ran the first time, so we ended up seeing <i>come</i> and <i>Come</i> both on the plot. But the general idea is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"30_most_frequent_2.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again there are some adjancies that could be telling. <i>away</i> and <i>girl</i> invokes certain love-related songs. <i>little</i> and <i>baby</i> are close (co-occurrence), also <i>like</i> and <i>want</i> (semantic similarity). <i>night</i> and <i>man</i> are closer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all good, but now that we have a list of all the words in each song, let's do a little unsupervised clustering to see what songs are topically similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
